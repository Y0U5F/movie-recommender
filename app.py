import pandas as pd
import numpy as np
import re
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import difflib
import os

# Ø¯Ø§Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
def clean_text(text):
    if not isinstance(text, str):
        return ''
    text = re.sub(r'[^\w\s]', '', text)  # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…
    return text.lower()

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙƒÙØ§Ø¡Ø©
@st.cache_data
def load_data():
    data_path = os.path.join('Data', 'movies.csv.gz')  # Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ·
    try:
        # Ø§Ù‚Ø±Ø§ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø£ÙˆÙ„Ø§Ù‹
        df = pd.read_csv(data_path, compression='gzip', nrows=0)
        available_columns = df.columns.tolist()

        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        required_columns = ['index', 'title', 'genres', 'keywords', 'tagline', 'cast', 'director']
        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ©
        optional_columns = ['release_year', 'overview']

        # ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        missing_required = [col for col in required_columns if col not in available_columns]
        if missing_required:
            st.error(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù: {missing_required}")
            return None

        # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù„ÙŠ Ù‡Ù†Ø­Ù…Ù„Ù‡Ø§ ÙØ¹Ù„Ù‹Ø§ (Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© + Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©)
        columns_to_load = required_columns + [col for col in optional_columns if col in available_columns]

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        movies_data = pd.read_csv(data_path, compression='gzip', usecols=columns_to_load)
        return movies_data
    except FileNotFoundError:
        st.error(f"Ù…Ù„Ù movies.csv.gz ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ {data_path}. ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ 'Data'.")
        return None
    except Exception as e:
        st.error(f"Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {str(e)}")
        return None

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
@st.cache_data
def process_data(movies_data):
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    features = ['genres', 'keywords', 'tagline', 'cast', 'director']
    
    # Ø¥Ø¶Ø§ÙØ© release_year Ùˆ overview Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯ÙŠÙ†
    if 'release_year' in movies_data.columns:
        features.append('release_year')
        movies_data['release_year'] = movies_data['release_year'].astype(str).fillna('')
    if 'overview' in movies_data.columns:
        features.append('overview')
        movies_data['overview'] = movies_data['overview'].fillna('')
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª
    for feature in features:
        movies_data[feature] = movies_data[feature].apply(clean_text)
    
    # Ø¥Ø¹Ø·Ø§Ø¡ Ø£Ù‡Ù…ÙŠØ© Ø£ÙƒØ¨Ø± Ù„Ù„Ù€ genres Ø¨ØªÙƒØ±Ø§Ø±Ù‡
    combined_features = (movies_data['genres'] + ' ' + movies_data['genres'] + ' ' +
                        movies_data['keywords'] + ' ' + movies_data['tagline'] + ' ' +
                        movies_data['cast'] + ' ' + movies_data['director'])
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
    if 'release_year' in movies_data.columns:
        combined_features += ' ' + movies_data['release_year']
    if 'overview' in movies_data.columns:
        combined_features += ' ' + movies_data['overview']
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù„ÙÙŠÙƒØªÙˆØ±Ø²
    vectorizer = TfidfVectorizer()
    feature_vectors = vectorizer.fit_transform(combined_features)
    similarity = cosine_similarity(feature_vectors)
    
    return similarity, movies_data

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØµÙŠØ©
def recommend_movies(movie_name, similarity, movies_data, top_n=20):
    list_of_all_titles = movies_data['title'].tolist()
    find_close_match = difflib.get_close_matches(movie_name, list_of_all_titles, n=1)
    
    if not find_close_match:
        return None, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙÙŠÙ„Ù… Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø¯Ø®Ù„."
    
    close_match = find_close_match[0]
    try:
        index_of_the_movie = movies_data[movies_data.title == close_match]['index'].values[0]
    except IndexError:
        return None, "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠÙ„Ù… ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
    
    similarity_score = list(enumerate(similarity[index_of_the_movie]))
    sorted_similar_movies = sorted(similarity_score, key=lambda x: x[1], reverse=True)
    
    recommendations = []
    for i, movie in enumerate(sorted_similar_movies[:top_n], 1):
        index = movie[0]
        try:
            title = movies_data[movies_data.index == index]['title'].values[0]
            recommendations.append((i, title))
        except IndexError:
            continue
    
    return recommendations, None

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("Ù†Ø¸Ø§Ù… ØªÙˆØµÙŠØ© Ø§Ù„Ø£ÙÙ„Ø§Ù… ğŸ¥")
st.write("Ø§Ø¯Ø®Ù„ Ø§Ø³Ù… ÙÙŠÙ„Ù… ÙˆÙ‡Ù†Ù‚ØªØ±Ø­Ù„Ùƒ Ø£ÙÙ„Ø§Ù… Ù…Ø´Ø§Ø¨Ù‡Ø©!")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
movies_data = load_data()

if movies_data is not None:
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    similarity, movies_data = process_data(movies_data)
    
    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ø§Ù„ÙÙŠÙ„Ù…
    movie_name = st.text_input("Ø§ÙƒØªØ¨ Ø§Ø³Ù… Ø§Ù„ÙÙŠÙ„Ù…:", placeholder="Ù…Ø«Ø§Ù„: Iron Man")
    
    if st.button("Ø§Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª"):
        if movie_name.strip() == "":
            st.warning("Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ Ø§Ø³Ù… ÙÙŠÙ„Ù….")
        else:
            recommendations, error = recommend_movies(movie_name, similarity, movies_data)
            
            if error:
                st.error(error)
            else:
                st.success(f"Ø§Ù„ØªÙˆØµÙŠØ§Øª Ù„ÙÙŠÙ„Ù…: {movie_name}")
                # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª ÙÙŠ Ø¬Ø¯ÙˆÙ„
                st.table(pd.DataFrame(recommendations, columns=["Ø§Ù„ØªØ±ØªÙŠØ¨", "Ø§Ø³Ù… Ø§Ù„ÙÙŠÙ„Ù…"]))

else:
    st.stop()
